{
  "news": {
    "items": [
      {
        "date": "2026.2",
        "title": "New Portfolio [netaobiakor.vercel.app](https://netaobiakor.vercel.app) launched! Welcome as you visit!",
        "content": "ðŸŽ‰ ðŸŽ‰ Congratulations to me and i thank Alex Peters for pushing me to have a portfolio."
      },
      {
        "date": "2026.1",
        "title": "[Unlocked 300 level at NOUN Nigeria] ",
        "content": "ðŸŒŠ I am now in 300 lvl in the University online"
      },
        {
        "date": "2024.3",
        "title": "[EscapeBills is founded) [![GitHub Repo stars](https://img.shields.io/github/stars/hpcaitech/Open-Sora?style=social)](https://github.com/onloopdev/escapebills) Released!",
        "content": "ðŸš€ EscapeBills a registered telecommunication vendor known for internet services, airtime VTU, cable TV subscriptions, electricity payment, converting airtime to cash, bitcoin buying and selling"
      },
       {
        "date": "2024.9",
        "title": "[Worked in WHAI AFRICA IN THE SUMMER ) ",
        "content": "ðŸ’¼ I worked at WHAI AFRICA during the Summer Vocation to teach Children Robotics and Basic Programming "
     },
     {
        "date": "2022.9",
        "title": "Accepted to Volunteer At STEMNOVO to teach STEM ",
        "content": "ðŸ“˜ Got accepted to STEMNOVO 2022. Congratulations to [Cyprian Obiakor]!"
      },
    ]
  },
   "projects": {
    "items": [
      {
        "title": "Video-Ocean Video Agent",
        "href": "https://video-ocean.com/en/agent",
        "dates": "Jun. 2025 - Present",
        "active": true,
        "description": "Video-Ocean Video Agent generates videos up to minutes with a few clicks, including voice and face.",
        "technologies": [],
        "authors": "",
        "links": [
          {
            "type": "Website",
            "href": "https://video-ocean.com/en/agent",
            "icon": "globe"
          }
        ],
        "image": "",
        "video": "https://files.zangwei.dev/proj-video-agent.mp4"
      },
      {
        "title": "Open-Sora [![GitHub Repo stars](https://img.shields.io/github/stars/hpcaitech/Open-Sora?style=social)](https://github.com/hpcaitech/Open-Sora)",
        "href": "https://github.com/hpcaitech/Open-Sora",
        "dates": "Mar. 2024 - Mar. 2025",
        "active": true,
        "description": "The world's first open-source Sora-like video generation model â€” bringing efficient, high-quality video production to everyone.",
        "technologies": [],
        "authors": "",
        "links": [
          {
            "type": "Github",
            "href": "https://github.com/hpcaitech/Open-Sora",
            "icon": "github"
          },
          {
            "type": "Open-Sora 1.2",
            "href": "https://arxiv.org/abs/2412.20404",
            "icon": "paper"
          },
          {
            "type": "Open-Sora 2.0",
            "href": "https://arxiv.org/abs/2503.09642",
            "icon": "paper"
          }
        ],
        "image": "/proj-open-sora.png",
        "video": ""
      },
      {
        "title": "Video-Ocean [![Video Ocean v2.0 â€“ #1 Product of the Day (Apr 12, 2025)](https://img.shields.io/badge/Product%20Hunt-%231%20of%20the%20Day-ff6154?logo=producthunt&logoColor=white)](https://www.producthunt.com/products/video-ocean-v2-0)",
        "href": "https://video-ocean.com/app",
        "dates": "April 2025 - Present",
        "active": true,
        "description": "Video-Ocean is a video generation platform that allows you to generate videos, images and audios with state-of-the-art models.",
        "technologies": [],
        "authors": "",
        "links": [
          {
            "type": "Website",
            "href": "https://video-ocean.com/app",
            "icon": "globe"
          }
        ],
        "image": "/proj-video-ocean.png",
        "video": ""
      },
      {
        "title": "Template for This Website",
        "href": "https://github.com/zhengzangw/nextjs-portfolio-blog-research",
        "dates": "Oct. 2025",
        "active": true,
        "description": "The template for this website, named Nextjs-Portfolio-Blog-Research. Built with Next.js, Tailwind CSS, Vercel, and more.",
        "image": "/proj-portfolio-template.png",
        "links": [
          {
            "type": "Github",
            "href": "https://github.com/zhengzangw/nextjs-portfolio-blog-research",
            "icon": "github"
          },
          {
            "type": "Docs",
            "href": "https://docs-nextjs-portfolio-blog-research.zangwei.dev/",
            "icon": "bookopen"
          },
          {
            "type": "Blog",
            "href": "/blog/note-nextjs-homepage",
            "icon": "newspaper"
          }
        ]
      },
      {
        "title": "ColossalChat [![GitHub Repo stars](https://img.shields.io/github/stars/hpcaitech/ColossalAI?style=social)](https://github.com/hpcaitech/ColossalAI)",
        "href": "https://github.com/hpcaitech/ColossalAI/tree/main/applications/ColossalChat",
        "dates": "Mar. 2023",
        "active": true,
        "description": "ColossalChat is a project to implement LLM with RLHF, powered by the Colossal-AI.",
        "technologies": [],
        "authors": "",
        "links": [
          {
            "type": "Github",
            "href": "https://github.com/hpcaitech/ColossalAI/tree/main/applications/ColossalChat",
            "icon": "github"
          },
          {
            "type": "Blog",
            "href": "https://medium.com/pytorch/colossalchat-an-open-source-solution-for-cloning-chatgpt-with-a-complete-rlhf-pipeline-5edf08fb538b",
            "icon": "newspaper"
          }
        ],
        "image": "/proj-colossalchat.png",
        "video": ""
      },
      {
        "title": "Instruction in the Wild [![GitHub Repo stars](https://img.shields.io/github/stars/XueFuzhao/InstructionWild?style=social)](https://github.com/XueFuzhao/InstructionWild)",
        "href": "https://github.com/XueFuzhao/InstructionWild",
        "dates": "Apr. 2024",
        "active": true,
        "description": "This project focuses on building a larger and more diverse instruction dataset by collecting 110K instructions from shared ChatGPT usage.",
        "technologies": [],
        "authors": "",
        "links": [
          {
            "type": "Github",
            "href": "https://github.com/XueFuzhao/InstructionWild",
            "icon": "github"
          }
        ],
        "image": "/proj-inst-wild.png",
        "video": ""
      }
    ]
  },
  "publications": {
    "items": [
      {
        "title": "CowClip Optimizer ![AAAI Distinguished Award](https://img.shields.io/badge/AAAI-Distinguished%20Paper%20Award-ff3557?logo=ai&logoColor=white&style=flat-square)",
        "href": "https://arxiv.org/abs/2204.06240",
        "dates": "AAAI 2023",
        "active": true,
        "description": "An optimizer that can train CTR prediction models with large batch (~128k)",
        "technologies": [
          "Rec",
          "Optim"
        ],
        "authors": "**Authors:** **Zangwei Zheng**, Pengtai Xu, Xuan Zou, Da Tang, Zhen Li, Chenguang Xi, Peng Wu, Leqi Zou, Yijie Zhu, Ming Chen, Xiangzhuo Ding, Fuzhao Xue, Ziheng Qin, Youlong Cheng, Yang You",
        "links": [
          {
            "type": "Paper",
            "href": "https://arxiv.org/abs/2204.06240",
            "icon": "paper"
          },
          {
            "type": "Github",
            "href": "https://github.com/bytedance/LargeBatchCTR",
            "icon": "github"
          }
        ],
        "image": "/proj-cowclip.png",
        "video": ""
      },
      {
        "title": "CAME Optimizer ![ACL Outstanding Paper Award](https://img.shields.io/badge/ACL-Outstanding%20Paper%20Award-ff3557?logo=ai&logoColor=white&style=flat-square)",
        "href": "https://arxiv.org/abs/2307.02047",
        "dates": "ACL 2023",
        "active": true,
        "description": "We introduce CAME, a confidence-guided optimizer that combines the fast convergence of adaptive methods with the low memory footprint of memory-efficient ones.",
        "technologies": [
          "LLM",
          "Optim"
        ],
        "authors": "**Authors:** Yang Luo, Xiaozhe Ren, **Zangwei Zheng**, Zhuo Jiang, Xin Jiang, Yang You",
        "links": [
          {
            "type": "Paper",
            "href": "https://arxiv.org/abs/2307.02047",
            "icon": "paper"
          },
          {
            "type": "Github",
            "href": "https://github.com/yangluo7/CAME",
            "icon": "github"
          },
          {
            "type": "Blog",
            "href": "/blog/proj-came",
            "icon": "newspaper"
          }
        ],
        "image": "/proj-came.png",
        "video": ""
      },
      {
        "title": "MERIT Optimizer",
        "href": "https://arxiv.org/abs/2508.20577",
        "dates": "ICML 2025",
        "active": true,
        "description": "MERIT constructs element-wise trust ratios to enable more robust update scaling by focusing on local weight structures.",
        "technologies": [
          "LLM",
          "Optim"
        ],
        "authors": "**Authors:** Yang Luo, **Zangwei Zheng**, Ziheng Qin, Zirui Zhu, Yong Liu, Yang You",
        "links": [
          {
            "type": "Paper",
            "href": "https://arxiv.org/abs/2508.20577",
            "icon": "paper"
          },
          {
            "type": "Github",
            "href": "https://github.com/NUS-HPC-AI-Lab/MERIT",
            "icon": "github"
          }
        ],
        "image": "/proj-merit.png",
        "video": ""
      },
      {
        "title": "Dynamic Sequence Parallelism",
        "href": "https://arxiv.org/abs/2403.10266",
        "dates": "ICML 2025",
        "active": true,
        "description": "A novel, elegant and super efficient sequence parallelism for multi-dimensional transformer architecture.",
        "technologies": [
          "VideoGen",
          "MLSys"
        ],
        "authors": "**Authors:** Xuanlei Zhao, Shenggan Cheng, Chang Chen, **Zangwei Zheng**, Ziming Liu, Zheming Yang, Yang You",
        "links": [
          {
            "type": "Paper",
            "href": "https://arxiv.org/abs/2403.10266",
            "icon": "paper"
          },
          {
            "type": "Github",
            "href": "https://github.com/NUS-HPC-AI-Lab/VideoSys",
            "icon": "github"
          },
          {
            "type": "Docs",
            "href": "https://github.com/NUS-HPC-AI-Lab/VideoSys/blob/master/docs/dsp.md",
            "icon": "bookopen"
          }
        ],
        "image": "/proj-dsp.png",
        "video": ""
      },
      {
        "title": "InfoBatch: Dataset Pruning on the Fly",
        "href": "https://arxiv.org/abs/2303.04947",
        "dates": "ICLR 2024",
        "active": true,
        "description": "InfoBatch accelerates model training by pruning easy samples and reweighting losses, achieving up to 40% faster training without sacrificing accuracy across diverse tasks.",
        "technologies": [
          "Efficient ML",
          "CV"
        ],
        "authors": "**Authors:** Ziheng Qin, Kai Wang, **Zangwei Zheng**, Jianyang Gu, Xiangyu Peng, Zhaopan Xu, Daquan Zhou, Lei Shang, Baigui Sun, Xuansong Xie, Yang You",
        "image": "/proj-infobatch.png",
        "links": [
          {
            "type": "Paper",
            "href": "https://arxiv.org/abs/2303.04947",
            "icon": "paper"
          },
          {
            "type": "Github",
            "href": "https://github.com/NUS-HPC-AI-Lab/InfoBatch",
            "icon": "github"
          },
          {
            "type": "Blog",
            "href": "/blog/proj-infobatch",
            "icon": "newspaper"
          }
        ]
      },
      {
        "title": "OpenMoE [![GitHub Repo stars](https://img.shields.io/github/stars/XueFuzhao/OpenMoE?style=social)](https://github.com/XueFuzhao/OpenMoE)",
        "href": "https://arxiv.org/abs/2402.01739",
        "dates": "ICML 2024",
        "active": true,
        "description": "OpenMoE is a project aimed at igniting the open-source MoE community! We are releasing a family of open-sourced Mixture-of-Experts (MoE) Large Language Models.",
        "technologies": [
          "LLM",
          "MoE",
          "Pre-training"
        ],
        "authors": "**Authors:** Fuzhao Xue, Zian Zheng, Yao Fu, Jinjie Ni, **Zangwei Zheng**, Wangchunshu Zhou, Yang You",
        "links": [
          {
            "type": "Paper",
            "href": "https://arxiv.org/abs/2402.01739",
            "icon": "paper"
          },
          {
            "type": "Github",
            "href": "https://github.com/XueFuzhao/OpenMoE",
            "icon": "github"
          },
          {
            "type": "Blog",
            "href": "https://xuefuzhao.notion.site/Aug-2023-OpenMoE-v0-2-Release-43808efc0f5845caa788f2db52021879",
            "icon": "newspaper"
          }
        ],
        "image": "/proj-openmoe.png",
        "video": ""
      },
      {
        "title": "MSIER",
        "href": "https://arxiv.org/abs/2404.12866",
        "dates": "ACL 2024",
        "active": true,
        "description": "A supervised retriever that improves multimodal in-context learning by optimally selecting text- and vision-based examples",
        "technologies": [
          "Multi-Modal",
          "In-Context Learning"
        ],
        "authors": "**Authors:** Yang Luo, **Zangwei Zheng**, Zirui Zhu, Yang You",
        "links": [
          {
            "type": "Paper",
            "href": "https://arxiv.org/abs/2404.12866",
            "icon": "paper"
          }
        ],
        "image": "/proj-msier.png"
      },
      {
        "title": "Sequence Schedule",
        "href": "https://arxiv.org/abs/2305.13144",
        "dates": "NeurIPS 2023",
        "active": true,
        "description": "Discovered that LLMs can foresee their response length â€” leading to Sequence Scheduling, an efficient LLM batch inference technique.",
        "technologies": [
          "LLM",
          "Efficient ML",
          "Inference"
        ],
        "authors": "**Authors:** **Zangwei Zheng**, Xiaozhe Ren, Fuzhao Xue, Yang Luo, Xin Jiang, Yang You",
        "links": [
          {
            "type": "Paper",
            "href": "https://arxiv.org/abs/2305.13144",
            "icon": "paper"
          },
          {
            "type": "Github",
            "href": "https://github.com/zhengzangw/Sequence-Scheduling",
            "icon": "github"
          },
          {
            "type": "Blog",
            "href": "/blog/proj-sequence-schedule",
            "icon": "newspaper"
          }
        ],
        "image": "/proj-sequence-schedule.png",
        "video": ""
      },
      {
        "title": "Token-Crisis",
        "href": "https://arxiv.org/abs/2305.13230",
        "dates": "NeurIPS 2023",
        "active": true,
        "description": "The available data can no longer keep pace with LLM development, but a carefully designed data repetition strategy can partially mitigate this limitation.",
        "technologies": [
          "LLM",
          "Pre-training"
        ],
        "authors": "**Authors:** Fuzhao Xue, Yao Fu, Wangchunshu Zhou, **Zangwei Zheng**, Yang You",
        "links": [
          {
            "type": "Paper",
            "href": "https://arxiv.org/abs/2305.13230",
            "icon": "paper"
          }
        ],
        "image": "/proj-to-repeat.png"
      },
      {
        "title": "Zero-Shot Continual Learning",
        "href": "https://arxiv.org/abs/2303.06628",
        "dates": "ICCV 2023",
        "active": true,
        "description": "A new benchmark and method to mitigate forgetting problem existed in the continual learning of large pretrained vision-language models.",
        "technologies": [
          "CL",
          "VLM",
          "Efficient ML"
        ],
        "authors": "**Authors:** **Zangwei Zheng**, Mingyuan Ma, Kai Wang, Ziheng Qin, Xiangyu Yue, Yang You",
        "links": [
          {
            "type": "Paper",
            "href": "https://arxiv.org/abs/2303.06628",
            "icon": "paper"
          },
          {
            "type": "Github",
            "href": "https://github.com/Thunderbeee/ZSCL",
            "icon": "github"
          },
          {
            "type": "Blog",
            "href": "/blog/proj-zscl",
            "icon": "newspaper"
          }
        ],
        "image": "/proj-zscl.png",
        "video": ""
      },
      {
        "title": "DoPrompt for Domain Adaptation",
        "href": "https://arxiv.org/abs/2208.08914",
        "dates": "2022",
        "active": true,
        "description": "DoPrompt is a simple and effective method to improve the performance of domain adaptation by using prompts.",
        "technologies": [
          "DA",
          "CV"
        ],
        "authors": "**Authors:** **Zangwei Zheng**, Xiangyu Yue, Kai Wang, Yang You",
        "links": [
          {
            "type": "Paper",
            "href": "https://arxiv.org/abs/2208.08914",
            "icon": "paper"
          },
          {
            "type": "Github",
            "href": "hhttps://github.com/zhengzangw/DoPrompt",
            "icon": "github"
          }
        ],
        "image": "/proj-prompt-da.png",
        "video": ""
      },
      {
        "title": "PCS Learning",
        "href": "https://arxiv.org/abs/2103.16765",
        "dates": "CVPR 2021",
        "active": true,
        "description": "An end-to-end Prototypical Cross-domain Self-Supervised Learning (PCS) framework for Few-shot Unsupervised Domain Adaptation (FUDA).",
        "technologies": [
          "DA",
          "CV",
          "SSL"
        ],
        "authors": "**Authors:** Xiangyu Yue, **Zangwei Zheng** (co-first-author), Shanghang Zhang, Yang Gao, Trevor Darrell, Kurt Keutzer, Alberto Sangiovanni Vincentelli",
        "links": [
          {
            "type": "Paper",
            "href": "https://arxiv.org/abs/2103.16765",
            "icon": "paper"
          },
          {
            "type": "Github",
            "href": "https://github.com/zhengzangw/PCS-FUDA",
            "icon": "github"
          },
          {
            "type": "Blog",
            "href": "https://xyue.io/pcs-fuda/index.html",
            "icon": "newspaper"
          }
        ],
        "image": "/proj-pcs-fuda.png",
        "video": ""
      }
    ]
  },
  "education": {
    "items": [
      {
        "school": "National University of Singapore",
        "href": "https://nus.edu.sg/",
        "degree": "Ph.D. in Computer Science",
        "logoUrl": "/icon/nus.png",
        "start": "2021",
        "end": "2025"
      },
      {
        "school": "Nanjing University",
        "href": "https://www.nju.edu.cn/en/",
        "degree": "Bachelor's Degree of Computer Science (top 2%)",
        "logoUrl": "/icon/nju.png",
        "start": "2017",
        "end": "2021"
      },
      {
        "school": "Jiangsu Xishan Senior High School",
        "href": "https://en.wikipedia.org/wiki/Xishan_Senior_High_School#:~:text=Jiangsu%20Xishan%20Senior%20High%20School,in%20computing%20and%20network%20facilities.",
        "degree": "High School Diploma",
        "logoUrl": "/icon/xishan.png",
        "start": "2014",
        "end": "2017"
      }
    ]
  },
  "work": {
    "items": [
      {
        "company": "HPC-AI Tech",
        "href": "https://www.hpcaitech.com/",
        "badges": [],
        "location": "Singapore",
        "title": "Tech Lead",
        "logoUrl": "/icon/hpc-ai.png",
        "start": "Dec. 2024",
        "end": "Present",
        "description": "Founder of Open-Sora and Video-Ocean."
      },
      {
        "company": "Bytedance",
        "href": "https://bytedance.com/",
        "badges": [],
        "location": "Singapore",
        "title": "Research Intern",
        "logoUrl": "/icon/bytedance.png",
        "start": "Jun. 2021",
        "end": "Jun. 2022",
        "description": "Work on large batch training for click-through rate prediction model, mentored by Xuan Zhou and Youlong Cheng."
      },
      {
        "company": "UC Berkeley",
        "href": "https://berkeley.edu/",
        "badges": [],
        "location": "(Remote) Berkeley, CA",
        "title": "Research Intern",
        "logoUrl": "/icon/ucb.png",
        "start": "Apr. 2020",
        "end": "May. 2021",
        "description": "Work on self-supervised learning and domain adaptation, mentored by Xiangyu Yue and Alberto Sangiovanni-Vincentelli."
      }
    ]
  },
  "awards": {
    "items": [
      {
        "year": 2023,
        "title": "Research Achievement Award of NUS"
      },
      {
        "year": 2023,
        "title": "ACL 2023 Outstanding Paper Award"
      },
      {
        "year": 2023,
        "title": "AAAI 2023 Distinguished Paper Award"
      },
      {
        "year": 2022,
        "title": "Papers with Code Contributor Award"
      },
      {
        "year": 2021,
        "title": "Outstanding Graduates of Nanjing University"
      },
      {
        "year": 2020,
        "title": "Outstanding Student of Nanjing University"
      },
      {
        "year": 2019,
        "title": "National Elite Program First-Class Scholarship (2 times, 2018â€“2019)"
      },
      {
        "year": 2019,
        "title": "Zheng Gang Overseas Study Scholarship"
      }
    ]
  },
  "invitedTalks": {
    "items": [
      {
        "host": "QbitAI",
        "url": "https://zhuanlan.zhihu.com/p/605329331",
        "date": "2023.02",
        "title": "Large Batch Training for CTR Prediction Model",
        "logoUrl": "/icon/qbitai.png"
      },
      {
        "host": "TechBeat",
        "url": "https://www.techbeat.net/talk-info?id=762",
        "date": "2023.03",
        "title": "Large Batch Training for Recommendation Model",
        "logoUrl": "/icon/techbeat.png"
      },
      {
        "host": "Distributed AI (DAI) Conference, invited by *Wenbin Li*",
        "url": "https://docs.google.com/presentation/d/123kehRyZqkr21ZWxjPyMU8_lMx6ki3g9vWIT3E1glQo/edit?usp=sharing",
        "date": "2023.12",
        "title": "Continual Learning on Pretrained Foundation Models",
        "logoUrl": "/icon/dai.png"
      },
      {
        "host": "National University of Singapore",
        "url": "",
        "date": "2024.03",
        "title": "Video Generation Model",
        "logoUrl": "/icon/nus.png"
      },
      {
        "host": "Nvidia, invited by *Yuyang Zhao*",
        "url": "",
        "date": "2025.03",
        "title": "Efficient Training with Open-Sora",
        "logoUrl": "/icon/nvidia.png"
      },
      {
        "host": "Tencent, invited by *Kai Wang*",
        "url": "https://docs.google.com/presentation/d/1-ds5dfFZARYxN60Q_4fjcDV-GFwYpOcCoJzSLIyak-Q/edit?usp=sharing",
        "date": "2025.09",
        "title": "AI Video Gen Model From Scratch",
        "logoUrl": "/icon/tencent.png"
      },
      {
        "host": "National University of Singapore",
        "url": "",
        "date": "2025.11",
        "title": "From Video Generation to Commercial Agents",
        "logoUrl": "/icon/nus.png"
      }
    ]
  },
  "teaching": {
    "items": [
      {
        "date": "Fall 2022",
        "location": "National University of Singapore",
        "title": "CS5242: Neural Networks and Deep Learning"
      },
      {
        "date": "Fall 2020",
        "location": "Nanjing University",
        "title": "Algorithm Analysis & Design"
      }
    ]
  },
  "skills": [
    "Python",
    "PyTorch",
    "TensorFlow",
    "ColossalAI",
    "vLLM",
    "LangGraph",
    "OpenAI API",
    "FastMCP",
    "FastAPI",
    "PostgreSQL",
    "TypeScript",
    "React",
    "Next.js",
    "Docker",
    "Terraform",
    "GitHub Actions",
    "GitLab CI/CD",
    "Grafana",
    "Vercel",
    "Figma",
    "Cursor",
    "C/C++",
    "FFmpeg"
  ],
  "reviewerConferences": [
    "NeurIPS",
    "ICLR",
    "CVPR",
    "ECCV",
    "AAAI"
  ],
  "reviewerJournals": [
    "Pattern Recognition",
    "TIP",
    "TSMC-S"
  ],
  "social": {
    "GitHub": {
      "name": "GitHub",
      "url": "https://github.com/zhengzangw",
      "icon": "github",
      "navbar": false,
      "content": true,
      "footer": true
    },
    "GoogleScholar": {
      "name": "Google Scholar",
      "url": "https://scholar.google.com/citations?user=FTqutJEAAAAJ&hl=en",
      "icon": "googlescholar",
      "navbar": false,
      "content": true,
      "footer": true
    },
    "orcid": {
      "name": "ORCID",
      "url": "https://orcid.org/0000-0001-7818-9534",
      "icon": "orcid",
      "navbar": false,
      "content": false,
      "footer": true
    },
    "dblp": {
      "name": "DBLP",
      "url": "https://dblp.org/pid/289/0376.html",
      "icon": "dblp",
      "navbar": false,
      "content": false,
      "footer": true
    },
    "researchgate": {
      "name": "ResearchGate",
      "url": "https://www.researchgate.net/profile/Zangwei-Zheng",
      "icon": "researchgate",
      "navbar": false,
      "content": false,
      "footer": true
    },
    "semanticScholar": {
      "name": "Semantic Scholar",
      "url": "https://www.semanticscholar.org/author/Zangwei-Zheng/2109654065",
      "icon": "semanticScholar",
      "navbar": false,
      "content": false,
      "footer": true
    },
    "LinkedIn": {
      "name": "LinkedIn",
      "url": "https://www.linkedin.com/in/zangweizheng/",
      "icon": "linkedin",
      "navbar": false,
      "content": true,
      "footer": true
    },
    "X": {
      "name": "X",
      "url": "https://x.com/zangweizheng",
      "icon": "x",
      "navbar": false,
      "content": true,
      "footer": true
    },
    "bluesky": {
      "name": "Bluesky",
      "url": "https://bsky.app/profile/zangwei.dev",
      "icon": "bluesky",
      "navbar": false,
      "content": false,
      "footer": true
    },
    "facebook": {
      "name": "Facebook",
      "url": "https://www.facebook.com/zangweizheng",
      "icon": "facebook",
      "navbar": false,
      "content": false,
      "footer": true
    },
    "instagram": {
      "name": "Instagram",
      "url": "https://www.instagram.com/zangweizheng",
      "icon": "instagram",
      "navbar": false,
      "content": false,
      "footer": true
    },
    "telegram": {
      "name": "Telegram",
      "url": "https://t.me/zangweizheng",
      "icon": "telegram",
      "navbar": false,
      "content": false,
      "footer": true
    },
    "discord": {
      "name": "Discord",
      "url": "https://discordapp.com/users/zangwei",
      "icon": "discord",
      "navbar": false,
      "content": false,
      "footer": true
    },
    "medium": {
      "name": "Medium",
      "url": "https://medium.com/@zangwei",
      "icon": "medium",
      "navbar": false,
      "content": false,
      "footer": true
    },
    "substack": {
      "name": "Substack",
      "url": "https://substack.com/@zangwei",
      "icon": "substack",
      "navbar": false,
      "content": false,
      "footer": true
    },
    "producthunt": {
      "name": "Product Hunt",
      "url": "",
      "icon": "producthunt",
      "navbar": false,
      "content": false,
      "footer": true
    },
    "Zhihu": {
      "name": "Zhihu",
      "url": "",
      "icon": "zhihu",
      "navbar": false,
      "content": true,
      "footer": true
    },
    "Xiaohongshu": {
      "name": "Xiaohongshu",
      "url": "",
      "icon": "xiaohongshu",
      "navbar": false,
      "content": false,
      "footer": true
    },
    "weibo": {
      "name": "Weibo",
      "url": "",
      "icon": "weibo",
      "navbar": false,
      "content": false,
      "footer": true
    },
    "wechat": {
      "name": "WeChat",
      "url": "",
      "icon": "wechat",
      "navbar": false,
      "content": false,
      "footer": true
    },
    "email": {
      "name": "Email",
      "url": "mailto:obiakorcyprian@gmail.com",
      "icon": "email",
      "navbar": false,
      "content": true,
      "footer": false
    },
    "rss": {
      "name": "RSS",
      "url": "",
      "icon": "rss",
      "navbar": false,
      "content": false,
      "footer": true
    },
    "calendly": {
      "name": "Calendly",
      "url": "",
      "icon": "calendly",
      "navbar": false,
      "content": false,
      "footer": false
    },
    "ethereum": {
      "name": "Ethereum",
      "url": "",
      "icon": "ethereum",
      "navbar": false,
      "content": false,
      "footer": true
    }
  }
}
